{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gathering Data\n",
    "First step was downloading all the necessary data.\n",
    "In the notebook all the data was downloaded by request library from Udayitie's server.\n",
    "The *twitter-archive-enhanced.csv* file was downloaded from [https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv] and is about 915692 bytes.\n",
    "The *image-predictions.tsv* file was downloaded from [https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv] and is about 335079 bytes. The extended twitter archive file was also downloaded from udacity, since after almost two weeks I still didn't get access from Twitter to it's API. The *tweets.txt* file was downloaded from [https://video.udacity-data.com/topher/2018/November/5be5fb7d_tweet-json/tweet-json.txt] and is 10609234 bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file was read into a dataframe with the pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was assessed by using the pandas dataframe methods like head(), tail(), sample(), info(), isnull(), value_counts(), apply() and slicing the datframe. Here are some but by far not all issues:\n",
    "### Quality:\n",
    "**twitter archive**\n",
    "- columns in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp contain NaN values or missing values\n",
    "- columns doggo, floofer, pupper, puppo contains sometimes a valid classification and sometimes all None\n",
    "- column name has sometimes None value or a name for the dog\n",
    "- column img_num contains sometimes a value other than 1, column doesn't have any information\n",
    "- column timestamp seems to have a consistent format, but datatype might be better in datetime\n",
    "\n",
    "**predictions**\n",
    "- columns p1, p2, p3 contains sometimes uppercase beginnings\n",
    "- some entries are not predictions of of dogs\n",
    "\n",
    "**twitter API**\n",
    "- columns in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_name, retweeted_status, quoted_status_id, quoted_status_id_str, quoted_status, geo, coordinates, place, contributors, possibly_sensitive, possibly_sensitive_appealable contain NaN or missing values\n",
    "- display_text_range contains the start and end_value\n",
    "- column retweeted is never True, favorited only 8 times\n",
    "- column lang contains undefined language abbreviations (und, eu), likely retweets ...\n",
    "\n",
    "**all**\n",
    "- tweet_id or id is in integer, for joining good, string is better after that\n",
    "\n",
    "### Tidiness:\n",
    "\n",
    "**twitter archive**\n",
    "- column source has HTML tags with an URL and the device description\n",
    "\n",
    "**predictions**\n",
    "- there are three prediction, but only one (the most likely one) is necessary\n",
    "- all dataframes should be merged, hence it's all about tweets about dogs\n",
    "\n",
    "**general issue**\n",
    "- some features are twice available and also implicitly given by other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning Data\n",
    "The first thing was joining all three dataframe on the twitter_id. After that it was an iterative approach of all listed issues. Sometimes other issues were found and fixed adhoc (some columns contained only ONE unique value). Also by fixing one issue, two were sometimes solved. Also manual change was sometimes neccessary (a dog name had to changed manually). Final step included removing all columns that didn't have any information or were collections of already available data in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Storing and Insight\n",
    "After finishing the cleaning step, the dataframe was saved by the dataframe method to_csv() as *twitter_archive_master.csv*\n",
    "Followed by reading this file in a dataframe and answering and also visualizing the questions:\n",
    "- What devices do users have?\n",
    "- What are the top 10 most favorite tweets?\n",
    "- What are the top 10 most retweeted tweets?\n",
    "- What day of the week and time of the day to people tweet the most?\n",
    "- What are the top 10 dog names (despite noname)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
